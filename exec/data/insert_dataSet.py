import os

import dotenv
import pandas as pd
import psycopg2
import io
from tqdm import tqdm
from dotenv import load_dotenv

# ============================
# 1. CSV ì •ì œ ë‹¨ê³„
# ============================
def clean_csv_files(source_folder, save_folder, columns_to_keep):
    os.makedirs(save_folder, exist_ok=True)
    for filename in os.listdir(source_folder):
        if not filename.endswith('.csv'):
            continue

        file_path = os.path.join(source_folder, filename)
        try:
            df = pd.read_csv(file_path, encoding='cp949',
                             usecols=columns_to_keep)
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, encoding='utf-8-sig',
                             usecols=columns_to_keep)

        df_filtered = df.drop_duplicates(subset=columns_to_keep)

        save_path = os.path.join(save_folder, f'filtered_{filename}')
        df_filtered.to_csv(save_path, index=False, encoding='utf-8-sig')
        print(f"âœ… {filename} ì •ì œ ì™„ë£Œ: {save_path}")


# ============================
# 2. ë³‘í•© + ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë‹¨ê³„
# ============================
category_mapping = {
    "FOOD": ["I201", "I202", "I203", "I204", "I205", "I206", "I207", "I210", "I211", "I212", "G204", "G205", "G206"],
    "TRANSPORT": ["G214", "N109", "S203"],
    "HOUSING": ["L102", "D101", "D102", "D103"],
    "MEDICAL": ["Q101", "Q102", "Q104", "G215", "M111"],
    "CULTURE": ["R102", "R103", "R104", "I101", "I102", "N110"],
    "SHOPPING": ["G202", "G203", "G208", "G209", "G210", "G211", "G212", "G216", "G217", "G218", "G219", "G220", "G221", "G222"],
    "EDUCATION": ["P105", "P106", "P107", "G213"],
    "ETC": ["M103", "M104", "M105", "M106", "M107", "M109", "M112", "M113", "M114", "M115",
             "N101", "N102", "N103", "N104", "N105", "N107", "N108", "N111",
             "S201", "S202", "S204", "S205", "S206", "S207", "S208", "S209", "S210", "S211", "G207"]
}

def get_category(code):
    for category, codes in category_mapping.items():
        if str(code)[:4] in codes:
            return category
    return "ETC"

def merge_cleaned_files(read_folder, output_path):
    all_data = []
    file_list = [f for f in os.listdir(read_folder) if f.endswith('.csv')]
    for filename in tqdm(file_list, desc="ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘"):
        file_path = os.path.join(read_folder, filename)
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig', usecols=['ìƒí˜¸ëª…', 'ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ì½”ë“œ'])
            df.columns = ['store_name', 'code']
            df['category'] = df['code'].apply(get_category)
            df['keyword'] = df['store_name']
            all_data.append(df[['category', 'keyword']])
        except Exception as e:
            print(f"âŒ {filename} ì½ê¸° ì‹¤íŒ¨: {e}")

    merged_df = pd.concat(all_data).drop_duplicates(subset='keyword')
    merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ë³‘í•©ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path} (ì´ {len(merged_df)}í–‰)")
    return merged_df


# ============================
# 3. DB ì—…ë¡œë“œ ë‹¨ê³„
# ============================
def upload_to_postgres(df, table_name, conn_info, chunk_size=10000):
    conn = psycopg2.connect(**conn_info)
    cur = conn.cursor()
    try:
        for i in tqdm(range(0, len(df), chunk_size), desc="ğŸ“¤ DB ì—…ë¡œë“œ ì¤‘"):
            chunk = df.iloc[i:i + chunk_size]
            buffer = io.StringIO()
            chunk.to_csv(buffer, index=False, header=False, encoding='utf-8')
            buffer.seek(0)
            cur.copy_from(buffer, table_name, sep=',', columns=('category', 'keyword'))
            conn.commit()
        print("âœ… ì „ì²´ ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        conn.rollback()
    finally:
        cur.close()
        conn.close()


# ============================
# Main ì‹¤í–‰ íë¦„
# ============================
if __name__ == "__main__":
    # í˜„ì¬ ì‹¤í–‰ ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ
    base_dir = os.path.dirname(os.path.abspath(__file__))
    source_folder = os.path.join(base_dir, 'read')
    save_folder = os.path.join(base_dir, 'save')
    merged_csv_path = os.path.join(base_dir, 'ì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨_ìƒê°€(ìƒê¶Œ)ì •ë³´_202412.csv')
    columns_to_keep = ['ìƒí˜¸ëª…', 'ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ì½”ë“œ']

    # DB ì ‘ì† ì •ë³´
    load_dotenv()

    conn_info = {
        'host': os.getenv('DB_HOST'),
        'port': int(os.getenv('DB_PORT')),
        'dbname': os.getenv('DB_NAME'),
        'user': os.getenv('DB_USER'),
        'password': os.getenv('DB_PASSWORD')
    }

    # ì‹¤í–‰ ë‹¨ê³„
    clean_csv_files(source_folder, save_folder, columns_to_keep)
    merged_df = merge_cleaned_files(save_folder, merged_csv_path)
    #upload_to_postgres(merged_df, 'spend_category', conn_info)